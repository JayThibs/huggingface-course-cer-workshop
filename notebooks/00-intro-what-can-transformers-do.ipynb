{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformers, what can they do?\n",
    "\n",
    "This is an introductory notebook to quickly go over the main tasks we can do with the `transformers` library.\n",
    "\n",
    "We'll start by import the `pipeline` module. The `pipeline` module is the \"higher-level\" API for the library. It allows you to quickly use pre-trained models on a given task. All you need to do is specify the task you want to perform. However, as we'll see, you can also specify the model you want to use.\n",
    "\n",
    "Notice in the next cell that we first instantiate the `pipeline` object, and then we classify the sentiment of a given sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9881473183631897}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier(\"I've been waiting for the Huggingface course my whole life!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the pre-trained model is downloaded from the Huggingface model hub, and then it is used to classify the sentiment of the sentence. In this case, the pre-trained model was a model from the BERT class of models: `DistilBERT-base-uncased`. The model was fine-tuned on English text with the task of classify the sentiment of a sentence.\n",
    "\n",
    "Note: once the model has been downloaded, it is cached on your machine. This speeds up future runs of the notebook since you won't have to download it again.\n",
    "\n",
    "Now, let's pass a list of strings to the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9881473183631897},\n",
       " {'label': 'NEGATIVE', 'score': 0.9995144605636597}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier([\"I've been waiting for the Huggingface course my whole life!\", \n",
    "\"I hate this so much\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three main steps involved when you pass some text to a pipeline:\n",
    "\n",
    "1. Tokenization: The text is preprocessed into a format the model can understand.\n",
    "2. Word vectors (tokenized/preprocessed inputs) do a forward-pass in the model.\n",
    "3. The predictions of the model are post-processed, so you can make sense of them.\n",
    "\n",
    "There are a ton of different tasks you can do with `pipeline`. Here are a few examples:\n",
    "\n",
    "* feature-extraction (get the vector representation of a text)\n",
    "* fill-mask\n",
    "* ner (named entity recognition)\n",
    "* question-answering\n",
    "* sentiment-analysis\n",
    "* summarization\n",
    "* text-generation\n",
    "* translation\n",
    "* zero-shot-classification\n",
    "\n",
    "We will cover some of these below.\n",
    "\n",
    "What do you think that the next task does?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'This is a course about the Transformers library',\n",
       " 'labels': ['education', 'business', 'politics'],\n",
       " 'scores': [0.8445993065834045, 0.11197397857904434, 0.043426692485809326]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\")\n",
    "classifier(\"This is a course about the Transformers library\",\n",
    "candidate_labels=[\"education\", \"politics\", \"business\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english)\n",
      "Downloading: 100%|██████████| 998/998 [00:00<00:00, 998kB/s]\n",
      "Downloading: 100%|██████████| 1.24G/1.24G [01:36<00:00, 13.9MB/s]\n",
      "Downloading: 100%|██████████| 60.0/60.0 [00:00<00:00, 62.3kB/s]\n",
      "Downloading: 100%|██████████| 208k/208k [00:00<00:00, 1.77MB/s]\n",
      "C:\\Users\\ThibJacq\\Anaconda3\\envs\\hf-windows\\lib\\site-packages\\transformers\\pipelines\\token_classification.py:136: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
      "  f'`grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"{aggregation_strategy}\"` instead.'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'ORG',\n",
       "  'score': 0.9947985,\n",
       "  'word': 'CER',\n",
       "  'start': 23,\n",
       "  'end': 26},\n",
       " {'entity_group': 'PER',\n",
       "  'score': 0.99895877,\n",
       "  'word': 'Gitane De Silva',\n",
       "  'start': 30,\n",
       "  'end': 45}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner = pipeline('ner', grouped_entities=True)\n",
    "ner(\"The current CEO of the CER is Gitane De Silva.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad (https://huggingface.co/distilbert-base-cased-distilled-squad)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.9861729145050049,\n",
       " 'start': 758,\n",
       " 'end': 801,\n",
       " 'answer': 'Bachelor of Arts in International Relations'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_answerer = pipeline('question-answering')\n",
    "question_answerer(question=\"Which bachelor's degree did Gitane De Silva recieve?\", \n",
    "context=\"\"\"The current CEO of the CER is Gitane De Silva. Ms. De Silva became the Chief Executive Officer of the CER in August 2020. Prior to joining the CER, she was a Special Advisor at TransAlta Corporation. She previously served as Alberta's Senior Representative to the United States and as Deputy Minister for Alberta International and Intergovernmental Relations.\n",
    "\n",
    "Before joining the Alberta Public Service, Ms. De Silva spent 12 years in Canada's Foreign Service as a specialist in Canada-U.S. relations, serving in a variety of roles, including as Consul General of Canada in Chicago and as Counsellor (Environment & Fisheries) at the Canadian Embassy in Washington, D.C. She also served as Deputy Head of Agency at Status of Women Canada.\n",
    "\n",
    "Ms. De Silva has a Bachelor of Arts in International Relations from the University of British Columbia and is a 2013 recipient of The International Alliance for Women (TIAW) World of Difference Award.\"\"\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "42b00840b7eaa013a76dbb9cad3644204271d8b923086de33fb5f3b75d0b142f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('berdi': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
